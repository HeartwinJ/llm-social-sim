{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COHORTS = 6 # 24\n",
    "COHORT_SIZE = 4 # 8\n",
    "NUM_ROUNDS = 3 # 75\n",
    "\n",
    "MEMORY_SIZE = 10\n",
    "MODEL_NAME= \"mistral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREATMENTS = {\n",
    "\t0.6: {\n",
    "\t\t('R', 'R'): (45, 45),\n",
    "\t\t('R', 'B'): (0, 42),\n",
    "\t\t('B', 'R'): (42, 0),\n",
    "\t\t('B', 'B'): (12, 12)\n",
    "\t},\n",
    "\t1: {\n",
    "\t\t('R', 'R'): (45, 45),\n",
    "\t\t('R', 'B'): (0, 40),\n",
    "\t\t('B', 'R'): (40, 0),\n",
    "\t\t('B', 'B'): (20, 20)\n",
    "\t},\n",
    "\t2: {\n",
    "\t\t('R', 'R'): (45, 45),\n",
    "\t\t('R', 'B'): (0, 35),\n",
    "\t\t('B', 'R'): (35, 0),\n",
    "\t\t('B', 'B'): (40, 40)\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://grateful-glowing-hog.ngrok-free.app/\"\n",
    "GENERATE_ENDPOINT = \"/ollama/api/generate\"\n",
    "CHAT_ENDPOINT = \"/ollama/api/chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gen = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Participant:\n",
    "\tdef __init__(self, id):\n",
    "\t\tself.id = id\n",
    "\t\tself.memory = []\n",
    "\t\tself.payout = 0\n",
    "\t\tself.rounds = 0\n",
    "\t\tself.prompt = \"\"\n",
    "\n",
    "\tdef __eq__(self, other):\n",
    "\t\treturn self.id == other.id\n",
    "\t\n",
    "\tdef set_prompt(self, prompt):\n",
    "\t\tself.prompt = prompt\n",
    "\t\n",
    "\tdef update_memory(self, ctx):\n",
    "\t\tself.memory.append(ctx)\n",
    "\t\tif len(self.memory) >= MEMORY_SIZE:\n",
    "\t\t\tself.memory.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "participant_ids = np.arange(1, NUM_COHORTS * COHORT_SIZE + 1, dtype=int)\n",
    "rand_gen.shuffle(participant_ids)\n",
    "# participants = np.array([(participant_id, np.empty((0,), dtype=list), 0) for participant_id in participant_ids], dtype=object)\n",
    "participants = [Participant(id) for id in participant_ids]\n",
    "cohorts = np.array_split(participants, NUM_COHORTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_cohorts = np.array_split(cohorts, len(TREATMENTS))\n",
    "cohort_treatments = list(zip(split_cohorts, TREATMENTS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_model(prompt, context):\n",
    "\tprint(f\"Prompt: {prompt}\")\n",
    "\tprint(f\"Context: {context}\")\n",
    "\tmessages = [\n",
    "\t\t*context,\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": prompt\n",
    "\t\t}\n",
    "\t]\n",
    "\tdata = {\n",
    "    \"model\": MODEL_NAME,\n",
    "\t\t\"messages\": messages,\n",
    "    \"stream\": False\n",
    "\t}\n",
    "\tprint(f\"Data: {data}\")\n",
    "\tres = requests.post(API_URL + CHAT_ENDPOINT, json=data).json()['response']\n",
    "\treturn [*messages, res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_choice(response):\n",
    "\tmatches = re.findall(\"{[A-Z]}\", response)\n",
    "\tif len(matches) > 0:\n",
    "\t\treturn matches[-1]\n",
    "\telse:\n",
    "\t\tmatches = re.findall(\"[RB]\", response)\n",
    "\t\tif len(matches) > 0:\n",
    "\t\t\treturn matches[-1]\n",
    "\t\telse:\n",
    "\t\t\treturn \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_start_prompt(treatment):\n",
    "\treturn f\"You are an undergraduate student participating in a lab experiment. You play a game with an anonymous player in which you simultaneously make a choice. Your payoff depends on both choices. If you both pick R, you each get {TREATMENTS[treatment][('R','R')][0]}$. If you choose R while they choose B, you get {TREATMENTS[treatment][('R','B')][0]}$, and they get {TREATMENTS[treatment][('R','B')][1]}$. Similarly, if you pick B while they pick R, you get {TREATMENTS[treatment][('B','R')][0]}$, and they get {TREATMENTS[treatment][('B','R')][1]}$. If you both pick B, you each earn {TREATMENTS[treatment][('B','B')][0]}$. The game has {NUM_ROUNDS} rounds. What's your choice? Perform reasoning as a human player. Append your choice letter in curly brackets as a last character.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cont_prompt(choice1, choice2, treatment):\n",
    "\treturn f\"You chose {choice1}. Your opponent chose {choice2}. Your payoff is {treatment[(choice1, choice2)][0]}. Your opponent's payoff is {treatment[(choice1, choice2)][1]}. Please play the next round.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_end_prompt(choice1, choice2, treatment, payouts):\n",
    "\treturn f\"You chose {choice1}. Your opponent chose {choice2}. Your payoff is {treatment[(choice1, choice2)][0]}. Your opponent's payoff is {treatment[(choice1, choice2)][1]}. The game is now over. Your total payoff was {sum(payouts[0]) + treatment[(choice1, choice2)][0]}. Your opponent's total payoff was {sum(payouts[1]) + treatment[(choice1, choice2)][1]}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cohorts_for_treatment, treatment in cohort_treatments:\n",
    "# \tfor cohort in cohorts_for_treatment:\n",
    "# \t\tfor participant in cohort:\n",
    "# \t\t\tp_memory = []\n",
    "# \t\t\to_memory = []\n",
    "# \t\t\tfor round in range(NUM_ROUNDS):\n",
    "# \t\t\t\tprint(participant)\n",
    "# \t\t\t\trand_participant = rand_gen.choice([x for x in cohort if x[0] != participant[0]])\n",
    "# \t\t\t\tprint(f\"Treatment: {treatment} - Round: {round + 1} - Participant 1: {participant} - Participant 2: {rand_participant}\")\n",
    "# \t\t\t\tif round == 0:\n",
    "# \t\t\t\t\tp_prompt = generate_start_prompt(treatment)\n",
    "# \t\t\t\t\to_prompt = generate_start_prompt(treatment)\n",
    "# \t\t\t\t\tp_context = [*p_memory]\n",
    "# \t\t\t\t\to_context = [*o_memory]\n",
    "# \t\t\t\telse:\n",
    "# \t\t\t\t\tp_prompt = generate_start_prompt(treatment)\n",
    "# \t\t\t\t\to_prompt = generate_start_prompt(treatment)\n",
    "# \t\t\t\t\tp_context = [*p_memory]\n",
    "# \t\t\t\t\to_context = [*o_memory]\n",
    "\t\t\t\t\n",
    "# \t\t\t\tp_memory = prompt_model(p_prompt, p_context)\n",
    "# \t\t\t\to_memory = prompt_model(o_prompt, o_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohorts_for_treatment, treatment in cohort_treatments:\n",
    "\tfor cohort in cohorts_for_treatment:\n",
    "\t\tfor round in range(NUM_COHORTS * COHORT_SIZE * NUM_ROUNDS // 2):\n",
    "\t\t\tparticipant, opponent = rand_gen.choice([x for x in cohort if x != participant and x.rounds < NUM_ROUNDS], size=2, replace=False)\n",
    "\n",
    "\t\t\tif participant.rounds == 0:\n",
    "\t\t\t\tparticipant.set_prompt(generate_start_prompt(treatment))\n",
    "\t\t\t\tctx, res = prompt_model(participant.prompt, participant.memory)\n",
    "\t\t\t\tchoice1 = get_choice(res)\n",
    "\t\t\t\tparticipant.update_memory(ctx)\n",
    "\t\t\t\n",
    "\t\t\tif opponent.rounds == 0:\n",
    "\t\t\t\topponent.set_prompt(generate_start_prompt(treatment))\n",
    "\t\t\t\tctx, res = prompt_model(opponent.prompt, opponent.memory)\n",
    "\t\t\t\tchoice2 = get_choice(res)\n",
    "\t\t\t\topponent.update_memory(ctx)\n",
    "\n",
    "\t\t\tparticipant.set_prompt(generate_cont_prompt(choice1, choice2, treatment))\n",
    "\t\t\topponent.set_prompt(generate_cont_prompt(choice2, choice1, treatment))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
