{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COHORTS = 6 # 24\n",
    "COHORT_SIZE = 4 # 8\n",
    "NUM_ROUNDS = 3 # 75\n",
    "\n",
    "MEMORY_DIR = \"memory\"\n",
    "MEMORY_SIZE = 10\n",
    "MODEL_NAME= \"mistral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREATMENTS = {\n",
    "\t0.6: {\n",
    "\t\t('R', 'R'): (45, 45),\n",
    "\t\t('R', 'B'): (0, 42),\n",
    "\t\t('B', 'R'): (42, 0),\n",
    "\t\t('B', 'B'): (12, 12)\n",
    "\t},\n",
    "\t1: {\n",
    "\t\t('R', 'R'): (45, 45),\n",
    "\t\t('R', 'B'): (0, 40),\n",
    "\t\t('B', 'R'): (40, 0),\n",
    "\t\t('B', 'B'): (20, 20)\n",
    "\t},\n",
    "\t2: {\n",
    "\t\t('R', 'R'): (45, 45),\n",
    "\t\t('R', 'B'): (0, 35),\n",
    "\t\t('B', 'R'): (35, 0),\n",
    "\t\t('B', 'B'): (40, 40)\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"http://127.0.0.1:11434\"\n",
    "GENERATE_ENDPOINT = \"/api/generate\"\n",
    "CHAT_ENDPOINT = \"/api/chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gen = np.random.default_rng(seed=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Participant:\n",
    "\tdef __init__(self, id):\n",
    "\t\tself.id = id\n",
    "\t\tself.memory = []\n",
    "\t\tself.payout = 0\n",
    "\t\tself.rounds = 0\n",
    "\t\tself.prompt = \"\"\n",
    "\n",
    "\tdef __eq__(self, other):\n",
    "\t\treturn self.id == other.id\n",
    "\t\n",
    "\tdef set_prompt(self, prompt):\n",
    "\t\tself.prompt = prompt\n",
    "\t\n",
    "\tdef update_memory(self, ctx):\n",
    "\t\tself.memory = [*ctx]\n",
    "\t\tif len(self.memory) >= MEMORY_SIZE:\n",
    "\t\t\tself.memory.pop(0)\n",
    "\t\tself.save_memory()\n",
    "\t\t\n",
    "\tdef save_memory(self):\n",
    "\t\twith open(f\"{MEMORY_DIR}/{self.id}.json\", \"wt\") as file:\n",
    "\t\t\tfile.write(json.dumps(self.memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "participant_ids = np.arange(101, NUM_COHORTS * COHORT_SIZE + 101, dtype=int)\n",
    "rand_gen.shuffle(participant_ids)\n",
    "participants = [Participant(id) for id in participant_ids]\n",
    "cohorts = np.array_split(participants, NUM_COHORTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_cohorts = np.array_split(cohorts, len(TREATMENTS))\n",
    "cohort_treatments = list(zip(split_cohorts, TREATMENTS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_model(prompt, context):\n",
    "\tmessages = [\n",
    "\t\t*context,\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": prompt\n",
    "\t\t}\n",
    "\t]\n",
    "\tdata = {\n",
    "    \"model\": MODEL_NAME,\n",
    "\t\t\"messages\": messages,\n",
    "    \"stream\": False\n",
    "\t}\n",
    "\tres = requests.post(API_URL + CHAT_ENDPOINT, json=data).json()\n",
    "\treturn [*messages, res['message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_choice(response):\n",
    "\tmatches = re.findall(\"{[A-Z]}\", response)\n",
    "\tif len(matches) > 0:\n",
    "\t\treturn matches[-1][1]\n",
    "\telse:\n",
    "\t\tmatches = re.findall(\"[RB]\", response)\n",
    "\t\tif len(matches) > 0:\n",
    "\t\t\treturn matches[-1]\n",
    "\t\telse:\n",
    "\t\t\treturn \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_start_prompt(treatment):\n",
    "\treturn f\"You are an undergraduate student participating in a lab experiment. You play a game with an anonymous player in which you simultaneously make a choice. Your payoff depends on both choices. If you both pick R, you each get {TREATMENTS[treatment][('R','R')][0]}$. If you choose R while they choose B, you get {TREATMENTS[treatment][('R','B')][0]}$, and they get {TREATMENTS[treatment][('R','B')][1]}$. Similarly, if you pick B while they pick R, you get {TREATMENTS[treatment][('B','R')][0]}$, and they get {TREATMENTS[treatment][('B','R')][1]}$. If you both pick B, you each earn {TREATMENTS[treatment][('B','B')][0]}$. The game has {NUM_ROUNDS} rounds. What's your choice? Perform reasoning as a human player. Append your choice letter in curly brackets as a last character.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cont_prompt(choice1, choice2, treatment):\n",
    "\treturn f\"You chose {choice1}. Your opponent chose {choice2}. Your payoff is {TREATMENTS[treatment][(choice1, choice2)][0]}$. Your opponent's payoff is {TREATMENTS[treatment][(choice1, choice2)][1]}$. Please play the next round.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_end_prompt(choice1, choice2, treatment, payout):\n",
    "\treturn f\"You chose {choice1}. Your opponent chose {choice2}. Your payoff is {TREATMENTS[treatment][(choice1, choice2)][0]}$. Your opponent's payoff is {TREATMENTS[treatment][(choice1, choice2)][1]}$. The game is now over. Your total payoff was {payout + TREATMENTS[treatment][(choice1, choice2)][0]}$.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(filename, row):\n",
    "\tnew_row = pd.DataFrame(row)\n",
    "\tif os.path.isfile(filename):\n",
    "\t\tdata = pd.read_csv(filename)\n",
    "\t\tdata = pd.concat([data, new_row])\n",
    "\t\tdata.to_csv(filename, index=False)\n",
    "\telse:\n",
    "\t\tdata = new_row\n",
    "\t\tdata.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohorts_for_treatment, treatment in cohort_treatments:\n",
    "\tfor cohort in cohorts_for_treatment:\n",
    "\t\tfor round in range(1, (NUM_COHORTS * COHORT_SIZE * NUM_ROUNDS // 2) + 1):\n",
    "\t\t\tparticipant, opponent = rand_gen.choice(cohort, size=2, replace=False)\n",
    "\n",
    "\t\t\tprint(f\"Treatment: {treatment} - Round {round}: {participant.id} vs {opponent.id}\")\n",
    "\n",
    "\t\t\tif participant.rounds == 0:\n",
    "\t\t\t\tprint(f\"First round of participant {participant.id}\")\n",
    "\t\t\t\tparticipant.set_prompt(generate_start_prompt(treatment))\n",
    "\n",
    "\t\t\tif opponent.rounds == 0:\n",
    "\t\t\t\tprint(f\"First round of participant {opponent.id}\")\n",
    "\t\t\t\topponent.set_prompt(generate_start_prompt(treatment))\n",
    "\n",
    "\t\t\tprint(f\"Prompting participant {participant.id}\")\n",
    "\t\t\tctx = prompt_model(participant.prompt, participant.memory)\n",
    "\t\t\tchoice1 = get_choice(ctx[-1]['content'])\n",
    "\t\t\tprint(f\"Got response for participant {participant.id} with choice: {choice1}\")\n",
    "\t\t\tparticipant.update_memory(ctx)\n",
    "\n",
    "\t\t\tprint(f\"Prompting participant {opponent.id}\")\n",
    "\t\t\tctx = prompt_model(opponent.prompt, opponent.memory)\n",
    "\t\t\tchoice2 = get_choice(ctx[-1]['content'])\n",
    "\t\t\tprint(f\"Got response for participant {opponent.id} with choice: {choice2}\")\n",
    "\t\t\topponent.update_memory(ctx)\n",
    "\n",
    "\t\t\tparticipant.rounds += 1\n",
    "\t\t\topponent.rounds += 1\n",
    "\n",
    "\t\t\tparticipant.payout = TREATMENTS[treatment][(choice1, choice2)][0]\n",
    "\t\t\topponent.payout = TREATMENTS[treatment][(choice1, choice2)][1]\n",
    "\n",
    "\t\t\tprint(f\"Saving results to file\")\n",
    "\t\t\tsave_results('experiment.csv', {'treatment': [treatment], 'round': [round], 'player1_id': [participant.id], 'player2_id': [opponent.id], 'player1_choice': [choice1], 'player2_choice': [choice2], 'player1_payout': [participant.payout], 'player2_payout': [opponent.payout]})\n",
    "\t\t\tprint(f\"Saved results to file\")\n",
    "\n",
    "\t\t\tif participant.rounds == NUM_ROUNDS:\n",
    "\t\t\t\tparticipant.set_prompt(generate_end_prompt(choice1, choice2, treatment, participant.payout))\n",
    "\t\t\telse:\n",
    "\t\t\t\tparticipant.set_prompt(generate_cont_prompt(choice1, choice2, treatment))\n",
    "\n",
    "\t\t\tif opponent.rounds == NUM_ROUNDS:\n",
    "\t\t\t\topponent.set_prompt(generate_end_prompt(choice1, choice2, treatment, opponent.payout))\n",
    "\t\t\telse:\n",
    "\t\t\t\topponent.set_prompt(generate_cont_prompt(choice2, choice1, treatment))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
